\subsection{Simulation of Reacting Fluid Flows}

Computer simulations of physical processes have existed since the World War II era, during which the development of early computers and researchers' access to them expanded greatly in pursuit of the atomic bomb. Broadly, the purpose of numerical simulations is to approximately reconstruct a physical process which has no tractable analytical solution and is either impossible or cost-prohibitive to experimentally measure. Rocket engines are ideal candidates for simulation due to their physical complexity and high cost of manufacturing and testing. This process is broken into its two major components: the modeling of fluid flows and the modeling of chemical reactions.

Numerical fluid modeling, or computational fluid dynamics (CFD), is based in the modeling of the Navier--Stokes equations (detailed in Sec.~\ref{sec:govEqs}), a set of partial differential equations which dictate the conservation of mass, momentum, and energy of a fluid flow. Except in special circumstances where a system cannot be treated as a continuum (such as nanofluidics and rarefied flows), the Navier--Stokes equations are a reliable description of fluid flows. However, analytical solutions for these equations are limited to extremely simple scenarios, such as Poiselle pipe flow or the Taylor--Greene vortex, where elements of the Navier--Stokes equations are neglected or the system exhibits some symmetry. In all other scenarios, certainly in any application of practical significance, analytical solutions are impossible and numerical methods must be used to obtain approximate solutions. In general, these methods amount to discretizing the spatial domain via methods such as finite-difference, finite-volume, finite-element, or discontinuous Galerkin methods, and marching the system forward in time with temporal discretization methods. These simulations have been successfully employed in the design and analysis of spacecraft~\cite{Murman2005}, automobiles~\cite{Kobayashi1992}, pumps~\cite{Shah2013}, and wind turbines~\cite{Sumner2010}, among many other applications. However, these models generally grow rapidly in cost with their spatial and temporal resolution. Many important physical phenomena, such as turbulence, require extremely small spatio-temporal resolutions to capture accurately. This necessitates the use of powerful supercomputers, which are inaccessible to all but select government and academic researchers, to compute direct numerical simulation (DNS) models which resolve all characteristic spatio-temporal scales. Most CFD practitioners must instead rely on low-fidelity approximations, such as Reynolds-averaged Navier--Stokes (RANS) models or large eddy simulations (LES)~\cite{Alfonsi2009,Mason1994}. These models describe the effect of unresolved physics on the resolved system in order to obtain a computationally-tractable solution. While inexpensive relative to DNS, these models often fail to accurately recreate important fluid behavior such as flow separation~\cite{Catalano2003} or correctly predict near-wall flow statistics~\cite{Nicoud2011}. Such low-cost models are useful as a first-order approximation, but they cannot match DNS in its accuracy and generalizability.

Chemical reaction modeling is also a well-studied field. Combustion, or any exothermic reaction of a fuel (often a hydrocarbon) with an oxidizer (often oxygen), is of particular interest due to its importance in generating electricity in gas turbines, mechanical power in piston and jet engines, and thrust in rocket engines. Chemical reactions are, at their core, interactions between individual molecules governed by the principles of quantum mechanics. There is an enormous number of molecules in practical chemical reaction systems (there are 1.882$\times 10^{22}$ molecules in just one gram of oxygen), and it is impossible to model their individual behaviors. As such, statistical or empirical models are used to describe the bulk behavior of chemicals in a mixture. Many detailed chemical reaction mechanisms have been developed which may include dozens of molecules and hundreds of reactions (e.g., the 52 species, 325 reaction GRI-Mech 3.0 mechanism for methane combustion~\cite{griMech}). These are, in general, not computationally tractable for simulations of large reacting systems. Reduced mechanisms seek to condense these complex processes with fewer chemical species and reactions, often using automated processes to generate accurate approximations with fewer than 20 species and reactions (e.g.,~\cite{Sung1998}), but sometimes fail to match experiments under certain conditions (e.g., very high temperature or equivalence ratio~\cite{Westbrook1984}, large hydrocarbons~\cite{Lu2008}).

The combination of these two fields, reacting turbulent flows, is less well-understood than its component fields for a variety of reasons. The characteristic spatio-temporal scales of chemical reactions are smaller even than those of turbulence, placing well-resolved simulations for all but fairly simple canonical problems well out of reach of modern supercomputers. For reference, recent well-resolved simulations of a rectangular premixed flame, running on 3,072 GPUs with advanced combusting flow software, still requires over $\sim$4 seconds to compute a single time step~\cite{HenrydeFrahan2022}. Additionally, the highly non-linear reaction source terms produce extremely stiff systems, making robust numerical solutions challenging~\cite{SuoYang2017}. Finally, relevant reacting flows often involve complex physics such liquid sprays~\cite{Masri2016}, radiative heat transfer~\cite{radCombustion}, and solid soot particulates~\cite{Omidvarborna2015}. Accurately modeling combustion in the presence of turbulence has been a particular difficulty for decades, but is extensively researched thanks to the importance of turbulence in efficient, reliable, and low-emission combustion~\cite{peters2000}. Many approximate models, including flamelet/progress variable~\cite{Pierce2001}, thickened flame~\cite{Colin2000}, and transported PDF models~\cite{Pope1985}, have been successfully applied to many practical combusting flow systems. However, many of these models struggle to accurately predict important features (such as local ignition and extinction~\cite{Jones2007}) in all flow configurations (such as partially-premixed flames~\cite{Knudsen2015}).

The above paragraphs illustrate two important points. First, the well-resolved simulations of combusting flows are extremely computationally expensive, largely driven by small, disparate, coupled spatio-temporal scales of turbulence and reactions, as well as by complex and stiff chemical kinetics. Second, although low-cost models such as RANS/LES, reduced chemical mechanisms, or flamelet models are constantly improving, they are often not generalizable to all circumstances and may not achieve significant cost reduction to be industrially-viable. Although advances in high-performance computing hardware and software continue to open new possibilities of bigger and faster computational physics, high-fidelity simulation of the complex multi-scale processes observed in rocket combustors remain oppressively expensive. Certainly, in the context of engineering design, in which many parameters of the combustor geometry, operating conditions, and propellant composition must be iteratively changed, a simulation runtime measured in weeks or months on massive supercomputers cannot be justified. In such a situation, performing an experiment is likely equally or less expensive, and generates much more useful operational data. This has stimulated inquiries into a third path, which seeks to learn learn low-cost surrogate models of complex systems from a small number of experiments or high-fidelity simulations. Such approaches can be broadly categorized as \textit{data-driven modeling}.