\section{Sample Selection Computations}

As discussed in Section~\ref{subsec:sampAlgos} and empirically tested in Section~\ref{sec:cvrc} as well as prior work by Wentland \textit{et al.}~\cite{Wentland2021}, constructing a sampled mesh for HPROMs which results in a stable and accurate solution at low sampling rates can be extremely challenging. Traditional methods, such as GNAT sampling originally proposed by Carlberg \textit{et al.}~\cite{Carlberg2013}, as well as simple random sampling, appear to perform suboptimally for HPROMs of complex reacting flow systems. Eigenvector-based sampling, originally developed by Zimmermann and Willox~\cite{Zimmermann2016} and simplified by Peherstorfer\textit{et al}~\cite{Peherstorfer2020}, has proven remarkably effective in enabling accurate HPROMs with very large computational cost savings. Based on findings here and in prior works~\cite{Peherstorfer2020,Wentland2021}, eigenvector-based sampling seems a natural choice for ensuring HPROM effectiveness. 

However, as demonstrated by offline cost measurements in Fig.~\ref{fig:cvrcSampCost}, eigenvector-based sampling can account for non-negligible portion of the full computational budget even when utilizing scalable, high-performance linear algebra tools such as PLATFORM~\cite{ArnoldMedabalimi2022}. Distributed-memory software is generally a necessity when operating on datasets in excess of $\bigO{10}$ GB, but such methods require special considerations. In particular, greedy methods implemented in distributed-memory applications are hampered by repeated sorting of non-contiguous memory and blocking, global reductions which are required to determine the minimum/maximum instance of the greedy sampling metric. Attempting to mitigate this communication overhead by limiting the total number of process invariably reduces the parallelism of evaluating the greedy metric. Hence, a delicate balancing act is required to enable efficient offline calculations.

One possible approach for mitigating the overall cost of the offline sampling calculations is suggested by the difference between the two GNAT sampling variants investigated in this thesis. In the original algorithm, $\mathtt{ceil}(\numSamps / \numResModes)$ are selected at every greedy iteration, while the alternative algorithm selected $\numVars$ at every greedy iteration. The latter is far more granular and approaches a more optimal solution, but incurs a much higher computational cost due to requiring potentially many more evaluations of the greedy metric. However, these approaches imply a spectrum, by which the number of samples to be selected is specified by the user at runtime. Smaller values should results in improved modeling accuracy, while higher values reduce offline costs. A compromise between these two effects may drastically reduce the computational burden of greedy sampling algorithms while ensuring stable and accurate HPROMs. Further, it may prove to be a useful approach in improving online sample mesh adaptation, where single-shot sampling may require exceptionally large sample meshes to ensure accuracy, as demonstrated in Chapter~\ref{chap:AdaptiveResults}.