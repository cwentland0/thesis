\section{AADEIM}

The AADEIM framework, originally posed by Peherstorfer and Willcox~\cite{Peherstorfer2015} and later refined by Peherstorfer~\cite{Peherstorfer2020Adaptive} is outlined here. This section borrows heavily from their notation for the sake of consistency. Only the sample mesh adaptation of AADEIM is utilized, though the trial basis adaptation method is detailed here for the sake of completeness.

The AADEIM procedure is predicated on the presentation of the fully discrete FOM O$\Delta$E as given in Eq.~\ref{eq:benResidual}, repeated here as
%
\begin{equation}
	\consVec^{\timeIdx-1} - \rhsResFunc{\consVec^{\timeIdx},\; \timeVar^{\timeIdx}} = \zeroVec.
\end{equation}
%
Again, this is an extremely counterintuitive way to write the evolution equations, but has the benefit of framing the residual in such a way as to motivate equating the trial basis $\consTrial$ and the regression basis $\deimBasis$, as outlined in Section~\ref{subsec:stateApproxDEIM}. From this frame of reference, AADEIM proposes adaptation of the trial basis $\consTrial$ as additive low-rank updates of the form
%
\begin{equation}
	\consTrial^{\timeIdx+1} = \consTrial^{\timeIdx} + \adeimAlpha^{\timeIdx} \left[\adeimBeta^{\timeIdx}\right]^\top.
\end{equation}
%
The matrices $\adeimAlpha \inRTwo{\numDOF}{\numRank}$ and $\adeimBeta \inRTwo{\numConsModes}{\numRank}$ compute the low-rank update, where $\numRank$ indicates the rank of the update. The original AADEIM procedure draws a distinction between sampling points (and the corresponding sampling operator $\sampMat \inRTwo{\numSamps}{\numDOF}$) and interpolation points (and its own operator $\sampMatInterp \inRTwo{\numResModes}{\numDOF}$), where the latter is linked to the original DEIM formulation. It is not necessary that the interpolation points be members of the sample set.

Given these sampling and interpolation operations, the trial basis update is formulated as the solution to the least-squares minimization of the error,
%
\begin{equation}\label{eq:aadeimAlphaBeta}
	\adeimAlpha^{\timeIdx} \left[\adeimBeta^{\timeIdx}\right]^\top = \argmin{\adeimAlpha \inRTwo{\numDOF}{\numRank},\; \adeimBeta \inRTwo{\numConsModes}{\numRank}} \left\Vert \sampMat^{\timeIdx} \left[\left[\consTrial^{\timeIdx} + \adeimAlpha \adeimBeta^\top \right] \left[\sampMatInterp^{\timeIdx} \consTrial^{\timeIdx}\right]^{-1} \sampMatInterp^{\timeIdx} - \identMat \right] \resWindow^{\timeIdx} \right\Vert_F^2,
\end{equation}
%
where the snapshot matrix $\resWindow^{\timeIdx} \inRTwo{\numDOF}{\numWindow}$ is defined as
%
\begin{align}
	\resWindow^{\timeIdx} &\defEq \left[\rhsResFunc{\consVecRom^{\timeIdx - \numWindow}}, \; \hdots \;, \; \rhsResFunc{\consVecRom^{\timeIdx - 1}}\right] \\
	&\defEq \left[\consVecRom^{\timeIdx - \numWindow + 1}, \; \hdots \;, \; \consVecRom^{\timeIdx} \right]
\end{align}
%
The window size $\numWindow \in \mathbb{N}_0$ represents the number of prior PROM solutions for which the regression error in Eq.~\ref{eq:aadeimAlphaBeta} is considered. That is, during the online solution of the PROM, the state $\consVecRom^{\timeIdx}$ is stored in $\resWindow^{\timeIdx}$, and the solution of least-squares minimization of the regression error of this solution updates the the trial basis $\consTrial$ during the PROM runtime. Note that in the work by Peherstorfer~\cite{Peherstorfer2020Adaptive}, those degrees of freedom which are \textit{not} sampled by $\sampMatInterp$ are simply reconstructed by $\sampMat \consVecRom = \sampMat \consTrial^{\timeIdx} \left[\sampMatInterp \consTrial^{\timeIdx}\right]^{-1} \sampMatInterp \left[\consVecCent + \consScale \consTrial \consVecCoef^{\timeIdx}\right]$.

The adaptation of the sample mesh is significantly simpler than that of the trial basis. The regression error is computed at every degree of freedom according to the formulation

\begin{equation}
	\mathbf{R}^{\timeIdx} = \left(\identMat - \deimBasis^{\timeIdx} \left[\sampMat^{\timeIdx} \deimBasis^{\timeIdx}\right] \sampMat^{\timeIdx} \resWindow^{\timeIdx}\right).
\end{equation}
Those $\numSamps$ degrees of freedom which incur the highest regression error are selected to construct the new sampling mesh defined by $\sampMat^{\timeIdx+1}$. Note that this step constitutes a \textit{loss of independence} from the full-order dimension $\numDOF$, as the error must be computed at every degree of freedom. The full-order model operator must be evaluated at an infrequent interval $\updateFreq$ to evaluate this. The effect of this query of the full-order system will be shown to be a major handicap of the method in later results.

\section{One-step Basis Adaptation}
%
The trial space adaptation proposed by Huang \textit{et al.}~\cite{Huang2022a} provides a simpler alternative to that provided by AADEIM. This method begins by suggesting a basis increment $\consTrialUpdate \inRTwo{\numDOF}{\numConsModes}$ which seeks to construct an improved trial space with which to represent the state vector computed from the FOM solution $\consVec$, given a fixed latent state $\consVecCoef$. This can be formalized at the $\timeIdx$th time step as
%
\begin{eqnarray}
	\consVec^{\timeIdx} = \consVecCent + \consScale \left[\consTrial^{\timeIdx} + \left[\consTrialUpdate\right]^{\timeIdx} \right] \consVecCoef^{\timeIdx},
\end{eqnarray}
%
where the FOM solution $\consVec^{\timeIdx}$ is computed in tandem with the low-dimensional PROM solution $\consVecCoef^{\timeIdx}$. Rearranging terms arrives at
%
\begin{eqnarray}
	\left[\consTrialUpdate\right]^{\timeIdx} \consVecCoef^{\timeIdx} = \consScaleInv \left[\consVec^{\timeIdx} - \consVecCent\right] - \consTrial^{\timeIdx} \consVecCoef^{\timeIdx}.
\end{eqnarray}
%
Obviously, this system of equations is underdetermined, attempting to solve for $\numDOF \times \numConsModes$ variables given $\numDOF$ equations. As such, there is no unique solution for $\left[\consTrialUpdate\right]^{\timeIdx}$. One solution suggested in~\cite{Huang2022a} is given as
%
\begin{equation}
	[\consTrialUpdate]^{\timeIdx} = \frac{\left[\consScaleInv\left[\consVec^{\timeIdx} - \consVecCent\right] - \consTrial^{\timeIdx} \consVecCoef^{\timeIdx}\right]\left[\consVecCoef^{\timeIdx}\right]^\top}{\left\Vert \consVecCoef^{\timeIdx} \right\Vert^2_2}
\end{equation}
%
Note that this approach is not strictly feasible given that the solution of the FOM equations $\consVec^{\timeIdx}$ must be computed in order to evaluate the trial basis update, thus defeating the purpose of the PROM. However, the usefulness of this approach becomes apparent when hyper-reduction is applied.

Two basis update steps are delineated: that occurring after iterations which only compute a HPROM solution, and that occurring after an iteration during which the sample mesh is updated as in the previous section. In the former case, the basis is only adapted at sampled points by the form
%
\begin{equation}
	\sampMat^{\timeIdx} [\consTrialUpdate]^{\timeIdx+1} = \sampMat^{\timeIdx} [\consTrialUpdate]^{\timeIdx} + \frac{\sampMat^{\timeIdx} \left[\consScaleInv\left[\consVec^{\timeIdx} - \consVecCent\right] - \consTrial^{\timeIdx} \consVecCoef^{\timeIdx}\right]\left[\consVecCoef^{\timeIdx}\right]^\top}{\left\Vert \consVecCoef^{\timeIdx} \right\Vert^2_2}
\end{equation}
%

% \begin{algorithm}
% 	\caption{Trial basis and sample mesh adaptation algorithm}\label{alg:adapt}
% 	\begin{algorithmic}
% 		\STATE temp
% 	\end{algorithmic}
% \end{algorithm}



% \begin{algorithm}
%     \caption{Basis and sampling adaptation}\label{alg:adapt}
%     \begin{algorithmic}

%     \STATE \texttt{init} $\leftarrow$ \texttt{istart} + \texttt{initWindow} - 1
%     \FOR{$\timeIdx$ = \texttt{istart} to \texttt{iend}}
%         \STATE $\consVecCoef^{\timeIdx} = \rhsApproxFunc{\consVecCoef^{\timeIdx-1}}$
%         \STATE $\consVecRom^{\timeIdx}[\sampVec^{\timeIdx-1}] = \consTrial^{\timeIdx-1}[\sampVec^{\timeIdx-1}, \; :] \consVecCoef^{\timeIdx}$
%         \IF{mod($\timeIdx$ - \texttt{init}, \texttt{basisInterval}) == 0 \AND $\timeIdx \ge$ \texttt{init}}
%             \STATE $\consVec^{\timeIdx}[\sampVec^{\timeIdx-1}] = \rhsFunc{\consVecRom^{\timeIdx - 1}[\sampVec^{\timeIdx-1}]}$
%             \STATE $\consTrial^{\timeIdx}$ = \texttt{OneStepAdapt}($\consVecCoef^{\timeIdx}, \; \consVecRom^{\timeIdx}[\sampVec^{\timeIdx-1}], \; \consVec^{\timeIdx}[\sampVec^{\timeIdx-1}]$)
%         \ELSE
%             \STATE $\consTrial^{\timeIdx} \leftarrow \consTrial^{\timeIdx - 1}$
%         \ENDIF
%         \IF{mod($n$ - \texttt{init}, \texttt{sampInterval}) == 0 \AND $\timeIdx \ge$ \texttt{init}}
%             \STATE $\consVec^{\timeIdx} = \rhsFunc{\consVecRom^{\timeIdx-1}}$
%             \STATE $\resVec^{\timeIdx} = \consVec^{\timeIdx} - \consTrial^{\timeIdx} [\consTrial^{\timeIdx}[\sampVec^{\timeIdx-1}, \; :]]^+ \consVec^{\timeIdx}[\sampVec^{\timeIdx - 1}]$
%             \STATE $\sampVec^{\timeIdx} = $ \texttt{argsort}$(\resVec^{\timeIdx})$[:\texttt{numSamps}]
%             % compute full-order residual
%             % calculate interpolation error
%             % argsort error
%             % pick samples
%         \ELSE
%             \STATE $\sampVec^{\timeIdx} \leftarrow \sampVec^{\timeIdx-1}$
%         \ENDIF
%     \ENDFOR

%     \end{algorithmic}
% \end{algorithm}